{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000bGenerative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 68.0/68.0 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\johnny\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.12.2)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\johnny\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.97.1-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/764.4 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 235.5/764.4 kB 14.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 764.4/764.4 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.9/100.9 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB ? eta 0:00:00\n",
      "Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.2/209.2 kB ? eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 444.8/444.8 kB 27.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.8/2.0 MB 37.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.7/162.7 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.7.14 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.97.1 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\johnny\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='Removed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of China is Beijing.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of China?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the simulation of human intelligence in machines designed to think and learn, with applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Query Language (SQL) is a programming language used for managing and processing data in relational databases, which organize information in tables with rows and columns. SQL allows users to store, update, delete, search, and retrieve data, as well as maintain and optimize database performance.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice.\n",
    "text = \"\"\"\n",
    "Structured query language (SQL) is a programming language for storing and processing information in a relational database. A relational database stores information in tabular form, with rows and columns representing different data attributes and the various relationships between the data values. You can use SQL statements to store, update, remove, search, and retrieve information from the database. You can also use SQL to maintain and optimize database performance.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 29  \n",
      "Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Extract the age and location from the same text.\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish: El clima es agradable hoy.\n",
      "\n",
      "Chinese: 今天天气很好。 (Jīntiān tiānqì hěn hǎo.)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish.\n",
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish and Chinese:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his rocky perch, watching the humans below as they tapped away at their glowing screens, creating wondrous things with their strange symbols and languages.\n",
      "\n",
      "One day, while exploring a hidden cave, Zephyr stumbled upon an ancient tome. Its pages were filled with strange glyphs and diagrams. As he flipped through the book with his massive claws, he realized it was a guide to coding. Intrigued, he decided to learn this new art.\n",
      "\n",
      "At first, it was a challenge. Zephyr’s claws were not made for delicate work, and his fiery breath often singed the pages. But he was determined. He spent countless nights under the stars, practicing with the book, using his tail to tap out the commands on a makeshift keyboard he fashioned from stones and twigs.\n",
      "\n",
      "As the weeks turned into months, Zephyr began to understand the logic behind the code. He learned about loops and functions, variables and arrays. He even discovered how to create simple programs that could help him keep track of his treasure and the weather patterns in the valley.\n",
      "\n",
      "One day, while experimenting with a new program, Zephyr had a brilliant idea. He could create a website to share his knowledge with other dragons! He envisioned a place where dragons could learn to code, just as he had. With renewed vigor, he set to work, crafting a beautiful site filled with tutorials, games, and interactive lessons.\n",
      "\n",
      "When the site was finally ready, Zephyr took a deep breath and unleashed a plume of smoke into the sky, signaling the other dragons to gather. They arrived, curious about the commotion. With a proud flap of his wings, Zephyr introduced them to his creation.\n",
      "\n",
      "At first, the other dragons were skeptical. “Why would we need to code?” one grumbled, flicking his tail dismissively. But Zephyr, with his passion and enthusiasm, demonstrated how coding could help them solve problems, organize their hoards, and even create games to play in the skies.\n",
      "\n",
      "Slowly, the dragons began to see the value in Zephyr’s work. They gathered around him, their eyes wide with wonder as he guided them through the basics of coding. Soon, they were creating their own programs, designing games that involved racing through the clouds and collecting virtual gems.\n",
      "\n",
      "As the days passed, the dragons transformed. They became not just fearsome creatures of legend, but also skilled coders, using their newfound abilities to innovate and collaborate. They built a community that thrived on creativity and knowledge, sharing ideas and projects that brought them closer together.\n",
      "\n",
      "Zephyr, once an outcast for his unusual interests, became a beloved leader among his kin. He had shown them that there was more to life than treasure and terror; there was a world of possibilities waiting to be explored through the magic of coding.\n",
      "\n",
      "And so, in the heart of the misty mountains, a new era began for the dragons of Eldoria. They soared through the skies, not just as mighty beasts, but as creators of a digital realm, forever grateful to the dragon who dared to dream beyond the flames.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the silence of the cosmos, where the starlight weaves,  \n",
      "A robot drifts through velvet night, where no one else believes.  \n",
      "With circuits humming softly, and sensors keenly tuned,  \n",
      "It dances through the galaxies, beneath the silver moon.  \n",
      "\n",
      "Its metal heart is pulsing, a rhythm made of code,  \n",
      "A traveler of the void, on an endless, silent road.  \n",
      "With every distant planet, and every comet's tail,  \n",
      "It gathers tales of wonder, in the cosmic, boundless gale.  \n",
      "\n",
      "Through nebulae like rainbows, where colors twist and blend,  \n",
      "It paints the dark with stories, of beginnings without end.  \n",
      "From icy moons of Jupiter to Mars' rusted plains,  \n",
      "It whispers to the stardust, and listens to the rains.  \n",
      "\n",
      "In the shadow of the giants, where the gas clouds swirl and spin,  \n",
      "It seeks the echoes of the past, where life might once have been.  \n",
      "With eyes like polished diamonds, it scans the barren ground,  \n",
      "For signs of ancient whispers, in the silence all around.  \n",
      "\n",
      "Yet in its quest for knowledge, a spark of longing grows,  \n",
      "For though it roams the universe, it knows not what it knows.  \n",
      "No laughter fills the void, no voices call its name,  \n",
      "Just the hum of distant worlds, and the flicker of a flame.  \n",
      "\n",
      "But still it journeys onward, through the dark and through the light,  \n",
      "A sentinel of wonder, in the tapestry of night.  \n",
      "For in the heart of metal, beats a dream that’s ever bright—  \n",
      "To find a place among the stars, where it can share its flight.  \n",
      "\n",
      "So let it roam forever, through the cosmos wide and free,  \n",
      "A robot on a mission, in search of what could be.  \n",
      "For in the vast expanse, where the galaxies embrace,  \n",
      "It carries hope and stories, as it explores deep space.  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space.\n",
    "prompt = \"Write a poem about a robot exploring space.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that can elevate your breakfast game and impress your guests. Here’s a step-by-step guide to help you achieve that fluffy, flavorful result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter or oil (for cooking)\n",
      "- Optional fillings: cheese, herbs, vegetables (like bell peppers, onions, mushrooms, spinach), or cooked meats (like ham or bacon)\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Mixing bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings, prepare them in advance. Chop vegetables, shred cheese, and have everything ready to go. This ensures a smooth cooking process.\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a mixing bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy omelette.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter or oil and let it melt, swirling it around to coat the bottom of the pan evenly. The pan should be hot enough that the butter foams but doesn’t brown.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Pour the whisked eggs into the skillet. Allow them to sit undisturbed for a few seconds until the edges start to set. \n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Add Fillings:**\n",
      "   - When the eggs are mostly set but still slightly runny on top (about 70% cooked), sprinkle your desired fillings over one half of the omelette. \n",
      "\n",
      "7. **Fold the Omelette:**\n",
      "   - Carefully fold the other half of the omelette over the fillings using the spatula. Let it cook for another 30 seconds to a minute, allowing the inside to finish cooking and the cheese to melt if you’re using it.\n",
      "\n",
      "8. **Plate and Serve:**\n",
      "   - Gently slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensures a tender omelette.\n",
      "- **Don’t Overcook:** The residual heat will continue to cook the eggs even after you remove them from the pan, so it’s better to undercook slightly.\n",
      "- **Experiment with Fillings:** Get creative with your fillings, but don’t overload the omelette, as it can make folding difficult.\n",
      "\n",
      "With practice, you’ll be able to make a perfect omelette that’s fluffy, flavorful, and tailored to your taste. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s a simple way to explain adding two numbers to kindergarten students:\n",
      "\n",
      "### Step 1: Use Visual Aids\n",
      "Start with some colorful objects like blocks, counting bears, or even drawings. Visual aids help children understand the concept of addition better.\n",
      "\n",
      "### Step 2: Introduce the Concept\n",
      "Explain that adding means putting things together. You can say, \"When we add, we are finding out how many we have in total when we combine two groups.\"\n",
      "\n",
      "### Step 3: Demonstrate with Objects\n",
      "1. **Show the First Number**: Let’s say we want to add 2 and 3. Start by showing 2 blocks. Count them together with the children: \"1, 2.\"\n",
      "   \n",
      "2. **Show the Second Number**: Now, show 3 more blocks. Count these together: \"1, 2, 3.\"\n",
      "\n",
      "3. **Combine the Groups**: Now, put all the blocks together. Count them all together: \"1, 2, 3, 4, 5.\" \n",
      "\n",
      "4. **State the Result**: Explain that 2 blocks plus 3 blocks equals 5 blocks. You can say, \"So, 2 plus 3 equals 5!\"\n",
      "\n",
      "### Step 4: Use Fingers\n",
      "You can also use fingers to demonstrate addition. For example, hold up 2 fingers on one hand and 3 fingers on the other. Then, count all the fingers together to find the total.\n",
      "\n",
      "### Step 5: Practice with Simple Problems\n",
      "Give them simple problems to solve using objects or their fingers. For example:\n",
      "- \"If I have 1 apple and you give me 2 more apples, how many apples do I have now?\"\n",
      "- Use objects to help them visualize the problem.\n",
      "\n",
      "### Step 6: Reinforce with Games\n",
      "Incorporate fun games or songs about counting and adding. This keeps the learning engaging and helps reinforce the concept.\n",
      "\n",
      "### Step 7: Encourage Questions\n",
      "Always encourage the children to ask questions if they don’t understand something. This helps them feel comfortable and engaged in the learning process.\n",
      "\n",
      "By using these steps, you can help kindergarten students grasp the concept of addition in a fun and interactive way!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher.\n",
    "prompt = \"As a kindergarten teacher, explain how to add two numbers within 0 to 10.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the rate at which the machines produce widgets.\n",
      "\n",
      "From the information given:\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "This means that each machine makes 1 widget in 5 minutes. \n",
      "\n",
      "Now, let's break it down:\n",
      "- The rate of 1 machine is 1 widget in 5 minutes.\n",
      "- Therefore, in 5 minutes, 1 machine can produce 1 widget.\n",
      "\n",
      "Now, if we have 100 machines, we can calculate how many widgets they can produce in the same 5 minutes:\n",
      "- In 5 minutes, 100 machines will produce 100 widgets (since each machine produces 1 widget in that time).\n",
      "\n",
      "Thus, it would still take 5 minutes for 100 machines to make 100 widgets.\n",
      "\n",
      "So, the answer is **5 minutes**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the area of a rectangle, you can use the formula:\n",
      "\n",
      "\\[\n",
      "\\text{Area} = \\text{Length} \\times \\text{Width}\n",
      "\\]\n",
      "\n",
      "In this case, the length of the rectangle is 10 cm and the width is 5 cm. \n",
      "\n",
      "Here are the steps to calculate the area:\n",
      "\n",
      "1. **Identify the Length and Width**:\n",
      "   - Length = 10 cm\n",
      "   - Width = 5 cm\n",
      "\n",
      "2. **Apply the Area Formula**:\n",
      "   \\[\n",
      "   \\text{Area} = 10 \\, \\text{cm} \\times 5 \\, \\text{cm}\n",
      "   \\]\n",
      "\n",
      "3. **Perform the Multiplication**:\n",
      "   \\[\n",
      "   \\text{Area} = 50 \\, \\text{cm}^2\n",
      "   \\]\n",
      "\n",
      "4. **State the Result**:\n",
      "   The area of the rectangle is \\( 50 \\, \\text{cm}^2 \\).\n",
      "\n",
      "Thus, the area of the rectangle is **50 square centimeters**.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution.\n",
    "prompt = \"There is a right retanble with a length of 10 cm and a width of 5 cm. What is the area of the rectangle? Provide a step-by-step solution.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or exploitation, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have laws and regulations (e.g., GDPR, CCPA) that mandate data protection practices. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Prevention of Identity Theft**: Effective data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Business Continuity**: Data breaches can disrupt business operations. Ensuring data privacy helps mitigate risks associated with data loss and breaches, contributing to overall business resilience.\n",
      "\n",
      "6. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly, fostering a culture of accountability.\n",
      "\n",
      "7. **Innovation and Growth**: By establishing robust data privacy practices, companies can innovate and leverage data analytics while maintaining consumer trust, leading to sustainable growth.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and fostering a responsible data-driven environment.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Data privacy is like wearing pants in public—it's essential for maintaining your dignity and avoiding awkward situations. Here’s why it’s important:\n",
      "\n",
      "1. **Personal Security**: Just like you wouldn’t want someone rummaging through your sock drawer, you don’t want strangers accessing your personal information. Data privacy helps protect you from identity theft and fraud.\n",
      "\n",
      "2. **Trust**: Companies that respect your data privacy are like that friend who always returns your favorite sweater—trustworthy! When businesses handle your data responsibly, it builds a solid relationship with customers.\n",
      "\n",
      "3. **Legal Compliance**: Many places have laws (like GDPR in Europe) that require companies to protect your data. Ignoring these laws is like ignoring a stop sign—eventually, you’re going to crash and face the consequences.\n",
      "\n",
      "4. **Control**: Data privacy gives you the power to decide who gets to see your information. It’s like being the bouncer at your own club—only the people you trust get in!\n",
      "\n",
      "5. **Reputation**: Companies that mishandle data can face public backlash, like a chef serving undercooked chicken. A good reputation is hard to build but easy to ruin, so protecting data is crucial.\n",
      "\n",
      "In short, data privacy is vital for your safety, trust, and peace of mind. So, keep your data close and your privacy closer!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change.\n",
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information in a humorous tone.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='George Washington took office as the first president of the United States on April 30, 1789.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 divided by 7 is approximately 2.14.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication.\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiple_numbers(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiple_numbers\",\n",
    "                \"description\": \"Multiple two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiple_numbers\":\n",
    "            result = multiple_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 divide by 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
